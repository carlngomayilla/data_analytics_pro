# pages/dashboard.py
import streamlit as st
import pandas as pd
import numpy as np

# === Fonction pour calculer l'indice de Gini ===
def gini_coefficient(x):
    """Calcule l'indice de Gini pour une s√©rie de valeurs num√©riques positives"""
    x = np.array(x.dropna())
    if len(x) == 0:
        return np.nan
    if np.any(x < 0):
        st.warning("L'indice de Gini est calcul√© sur des valeurs absolues (n√©gatives ignor√©es).")
        x = np.abs(x)
    x = np.sort(x)
    n = len(x)
    cumx = np.cumsum(x)
    gini = (2 * np.sum((np.arange(1, n+1) * x)) / (n * cumx[-1])) - (n + 1) / n
    return round(gini, 4)

def main(df):
    st.title("üìä Tableau de bord ‚Äì Statistiques descriptives et analytiques")

    if df is None or df.empty:
        st.info("Aucune donn√©e charg√©e. Utilisez la barre lat√©rale pour uploader un fichier.")
        return

    # === 1. Statistiques descriptives num√©riques avec Gini ===
    st.header("1. Statistiques descriptives num√©riques (avec indice de Gini)")

    numeric_cols = df.select_dtypes(include='number').columns.tolist()
    if numeric_cols:
        desc = df[numeric_cols].describe(percentiles=[.05, .1, .25, .5, .75, .9, .95]).T
        desc['mode'] = df[numeric_cols].mode().iloc[0]
        desc['skewness'] = df[numeric_cols].skew()
        desc['kurtosis'] = df[numeric_cols].kurtosis()
        desc['variance'] = df[numeric_cols].var()
        desc['cv (%)'] = (desc['std'] / desc['mean'] * 100).round(2)
        
        # Ajout de l'indice de Gini
        gini_values = [gini_coefficient(df[col]) for col in numeric_cols]
        desc['Gini'] = gini_values
        
        desc = desc.round(3)
        st.dataframe(desc, use_container_width=True)
        
        st.info("**Indice de Gini** : 0 = √©galit√© parfaite, 1 = in√©galit√© maximale. Tr√®s utilis√© pour mesurer la concentration (revenus, ventes, etc.).")
    else:
        st.info("Aucune colonne num√©rique d√©tect√©e.")

    # === 2. Statistiques de fr√©quence et r√©partition ===
    st.header("2. Statistiques de fr√©quence et r√©partition")

    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    if categorical_cols:
        for col in categorical_cols:
            with st.expander(f"R√©partition de {col}"):
                freq = df[col].value_counts().head(20)
                freq_rel = df[col].value_counts(normalize=True).head(20) * 100
                table = pd.DataFrame({
                    "Valeur": freq.index.astype(str),
                    "Fr√©quence absolue": freq.values,
                    "Fr√©quence relative (%)": freq_rel.values.round(2)
                })
                st.dataframe(table, use_container_width=True)
    else:
        st.info("Aucune colonne cat√©gorielle d√©tect√©e.")

    # === 3. Qualit√© des donn√©es ===
    st.header("3. Statistiques de qualit√© des donn√©es")

    missing = df.isna().sum()
    missing_pct = (missing / len(df)) * 100
    quality = pd.DataFrame({
        "Colonne": df.columns,
        "Valeurs manquantes": missing.values,
        "Taux manquant (%)": missing_pct.round(2).values,
        "Doublons totaux": [df.duplicated().sum()] * len(df.columns)
    })
    st.dataframe(quality, use_container_width=True)

    col1, col2, col3 = st.columns(3)
    col1.metric("Taux global de valeurs manquantes", f"{missing_pct.mean():.2f}%")
    col2.metric("Nombre de lignes dupliqu√©es", df.duplicated().sum())
    col3.metric("Compl√©tude moyenne", f"{(1 - missing_pct.mean()/100)*100:.2f}%")

    # === 4. Statistiques bivari√©es (corr√©lations) ===
    st.header("4. Statistiques bivari√©es (corr√©lations)")

    if len(numeric_cols) >= 2:
        corr_pearson = df[numeric_cols].corr(method='pearson')
        corr_spearman = df[numeric_cols].corr(method='spearman')
        st.subheader("Corr√©lation de Pearson")
        st.dataframe(corr_pearson.round(3), use_container_width=True)
        st.subheader("Corr√©lation de Spearman")
        st.dataframe(corr_spearman.round(3), use_container_width=True)
    else:
        st.info("Pas assez de colonnes num√©riques pour les corr√©lations.")

    # === 5. Statistiques temporelles ===
    st.header("5. Statistiques temporelles")

    date_cols = df.select_dtypes(include='datetime64[ns]').columns.tolist()
    if date_cols:
        date_col = date_cols[0]
        st.write(f"Analyse temporelle sur **{date_col}**")
        df_sorted = df.sort_values(date_col).dropna(subset=[date_col])
        duration_days = (df_sorted[date_col].max() - df_sorted[date_col].min()).days
        st.metric("Dur√©e totale (jours)", duration_days)
        st.metric("Nombre de dates uniques", df_sorted[date_col].dt.date.nunique())
    else:
        st.info("Aucune colonne de type date d√©tect√©e.")

    # === 6. KPI et indicateurs globaux ===
    st.header("6. Indicateurs cl√©s (KPI)")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Observations totales", len(df))
    col2.metric("Variables", len(df.columns))
    col3.metric("Taux de compl√©tude moyen", f"{(1 - df.isna().mean().mean()) * 100:.2f}%")
    col4.metric("Densit√© de donn√©es", f"{(df.notna().sum().sum() / (len(df) * len(df.columns))) * 100:.2f}%")

    st.success("Toutes les statistiques descriptives et analytiques sont disponibles sous forme tabulaire.")